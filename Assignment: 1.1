Q1. Various sources of Big Data.
A1. a)Docs
    b)Media
    c)Data storage
    d)Social Media
    e)Business apps
    f)Archives
    g)Public web
    h)Sensor data
    i)Machine log data
    
 Q2. 3 V's of Big Data.
 A2. a)Volume: Data is in the format of videos, musics and large images on our social media channels. It is very common to have Terabytes and Petabytes of the storage system for enterprises.
      As the database grows the applications and architecture built to support the data needs to be reevaluated quite often. The big volume indeed represents Big Data.
     b)Velocity: There was a time when we used to believe that data of yesterday is recent. The matter of the fact newspapers is still
     following that logic. However, news channels and radios have changed how fast we receive the news. Today, people reply on social media
     to update them with the latest happening. On social media sometimes a few seconds old messages (a tweet, status updates etc.) is not 
     something interests users. They often discard old messages and pay attention to recent updates.
     The data movement is now almost real time and the update window has reduced to fractions of the seconds. 
     This high velocity data represent Big Data.
    c)Variety: Data can be stored in multiple format. For example database, excel, csv, access or for the matter of the fact,
     it may be in the form of video, SMS, pdf. The real world have data in many different formats and that is the challenge we need to
     overcome with the Big Data. This variety of the data represent  represent Big Data.
    
 Q3.Horizontal Scaling and Vertical Scaling.
 A3.Horizontal scaling means that you scale by adding more machines into your pool of resources,it can be said as the scale out process
 which is the best solution to overcome one of  the challenges of big data whereas Vertical scaling means that you scale by adding more power
 (CPU, RAM) to an existing machine,it is also knows as scale up.It is basically a monolithic system but more costlier the the hoizontal scaling.
 

Q4. Need and Working of Hadoop .
A4 Need:
  The complexity of modern analytics need is outstripping the available computing power of legacy systems.
  With its distributed processing, Hadoop can handle large volumes of structured and unstructured data more efficiently
  than the traditional enterprise data warehouse as Hadoop is open source and can run on commodity hardware, the initial cost savings are
  dramatic and continue to grow as your organizational data grows. Additionally, Hadoop has a robust Apache community behind it
  that continues to contribute to its advancement.
  Working:
  Hadoop is a open source java based programming framework.It is based on GFS(google file system).It basically works in two parts.
  1 HDFS(Hadoop distributed file system)this system is used for storing the data that enables faster data transfer among the nodes.
  2 Map Reduce: It is used to process the stored data.
